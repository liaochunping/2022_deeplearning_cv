{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 02-1: due 2022/03/31 23:59 (30%)\n",
    "\n",
    "#### - In this part, you should calculate the forward pass and backpropagation manually and there is no need for any coding.\n",
    "\n",
    "#### - Please scan your hand-writting calculation and save it as HW2-1.pdf\n",
    "\n",
    "#### - By running the following script, you can check your answer and observe how to do the backpropagation in PyTorch.\n",
    "\n",
    "#### - You can change the iterations in script to observe how will the loss change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Please do the forward pass and backpropagation with a neural network as below, the input is 2 and the target is 1. Also, calculate the quadratic loss, \n",
    "##### i.e, $$Loss = \\frac{1}{2}(y-y^*)^2$$ \n",
    "##### Please update the parameters twice, i.e., do two back propagation operations, and use the learning rate 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_ex.png](https://github.com/tingyan08/Deep-Learning-and-Computer-Vision/blob/main/HW2/img/HW2-1.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([2], dtype= torch.float32)\n",
    "y = torch.tensor([1], dtype= torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half of the sum square error\n",
    "def loss(y, pred):\n",
    "    return ((pred-y)**2).sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show parameters\n",
    "def show_parameters(i, X, model):\n",
    "    print(f\"Iters {i}\")\n",
    "    print(\"Input:\")\n",
    "    print(X)\n",
    "    for layer_name, layers in model.named_modules():\n",
    "        print(\"-----------------------\")\n",
    "        if not isinstance(layers, nn.Sequential):\n",
    "            for param_name, param in layers.named_parameters():\n",
    "                print(f\"{layer_name} {param_name} {param}\")\n",
    "                print(f\"{layer_name} {param_name} Gradient\")\n",
    "                print(param.grad)\n",
    "            print(f\"{layer_name} output:\")\n",
    "            X = layers(X)\n",
    "            print(X)\n",
    "            \n",
    "    print(\"===============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for name, i in model.named_modules():\n",
    "        if isinstance(i, nn.Linear):\n",
    "            nn.init.constant_(i.weight.data, 1)\n",
    "            nn.init.constant_(i.bias.data, -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Layer1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (Layer2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (ReLU2): ReLU()\n",
      "  (Layer3): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iters 0\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[1.],\n",
      "        [1.]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[14.],\n",
      "        [14.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-0.5000, -0.5000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([7., 7.])\n",
      "Layer1 output:\n",
      "tensor([1.5000, 1.5000], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([1.5000, 1.5000], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[5.2500, 5.2500],\n",
      "        [5.2500, 5.2500]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.5000, -0.5000], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([3.5000, 3.5000])\n",
      "Layer2 output:\n",
      "tensor([2.5000, 2.5000], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([2.5000, 2.5000], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[1., 1.]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[8.7500, 8.7500]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.5000], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([3.5000])\n",
      "Layer3 output:\n",
      "tensor([4.5000], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 1\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.8500], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-1.8500])\n",
      "Layer3 output:\n",
      "tensor([-0.8500], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 2\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.6650], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-1.6650])\n",
      "Layer3 output:\n",
      "tensor([-0.6650], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 3\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.4985], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-1.4985])\n",
      "Layer3 output:\n",
      "tensor([-0.4985], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 4\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.3487], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-1.3486])\n",
      "Layer3 output:\n",
      "tensor([-0.3487], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 5\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.2138], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-1.2138])\n",
      "Layer3 output:\n",
      "tensor([-0.2138], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 6\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([-0.0924], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-1.0924])\n",
      "Layer3 output:\n",
      "tensor([-0.0924], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 7\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.0168], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.9832])\n",
      "Layer3 output:\n",
      "tensor([0.0168], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 8\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.1152], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.8848])\n",
      "Layer3 output:\n",
      "tensor([0.1152], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 9\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.2036], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.7964])\n",
      "Layer3 output:\n",
      "tensor([0.2036], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 10\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.2833], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.7167])\n",
      "Layer3 output:\n",
      "tensor([0.2833], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 11\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.3549], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.6451])\n",
      "Layer3 output:\n",
      "tensor([0.3549], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 12\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.4195], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.5805])\n",
      "Layer3 output:\n",
      "tensor([0.4195], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 13\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.4775], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.5225])\n",
      "Layer3 output:\n",
      "tensor([0.4775], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 14\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.5298], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.4702])\n",
      "Layer3 output:\n",
      "tensor([0.5298], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 15\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.5768], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.4232])\n",
      "Layer3 output:\n",
      "tensor([0.5768], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 16\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.6191], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.3809])\n",
      "Layer3 output:\n",
      "tensor([0.6191], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 17\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.6572], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.3428])\n",
      "Layer3 output:\n",
      "tensor([0.6572], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 18\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.6915], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.3085])\n",
      "Layer3 output:\n",
      "tensor([0.6915], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 19\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.7223], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.2777])\n",
      "Layer3 output:\n",
      "tensor([0.7223], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 20\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.7501], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.2499])\n",
      "Layer3 output:\n",
      "tensor([0.7501], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 21\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.7751], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.2249])\n",
      "Layer3 output:\n",
      "tensor([0.7751], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 22\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.7976], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.2024])\n",
      "Layer3 output:\n",
      "tensor([0.7976], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 23\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.8178], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.1822])\n",
      "Layer3 output:\n",
      "tensor([0.8178], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 24\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.8360], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.1640])\n",
      "Layer3 output:\n",
      "tensor([0.8360], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 25\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.8524], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.1476])\n",
      "Layer3 output:\n",
      "tensor([0.8524], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 26\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.8672], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.1328])\n",
      "Layer3 output:\n",
      "tensor([0.8672], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 27\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.8805], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.1195])\n",
      "Layer3 output:\n",
      "tensor([0.8805], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 28\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.8924], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.1076])\n",
      "Layer3 output:\n",
      "tensor([0.8924], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 29\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9032], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0968])\n",
      "Layer3 output:\n",
      "tensor([0.9032], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 30\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9129], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0871])\n",
      "Layer3 output:\n",
      "tensor([0.9129], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 31\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9216], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0784])\n",
      "Layer3 output:\n",
      "tensor([0.9216], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 32\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9294], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0706])\n",
      "Layer3 output:\n",
      "tensor([0.9294], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 33\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9365], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0635])\n",
      "Layer3 output:\n",
      "tensor([0.9365], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 34\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9428], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0572])\n",
      "Layer3 output:\n",
      "tensor([0.9428], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 35\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9485], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0515])\n",
      "Layer3 output:\n",
      "tensor([0.9485], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 36\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9537], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0463])\n",
      "Layer3 output:\n",
      "tensor([0.9537], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 37\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9583], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0417])\n",
      "Layer3 output:\n",
      "tensor([0.9583], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 38\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9625], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0375])\n",
      "Layer3 output:\n",
      "tensor([0.9625], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 39\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9662], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0338])\n",
      "Layer3 output:\n",
      "tensor([0.9662], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 40\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9696], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0304])\n",
      "Layer3 output:\n",
      "tensor([0.9696], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 41\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9727], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0273])\n",
      "Layer3 output:\n",
      "tensor([0.9727], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 42\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9754], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0246])\n",
      "Layer3 output:\n",
      "tensor([0.9754], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 43\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9779], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0221])\n",
      "Layer3 output:\n",
      "tensor([0.9779], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 44\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9801], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0199])\n",
      "Layer3 output:\n",
      "tensor([0.9801], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 45\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9821], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0179])\n",
      "Layer3 output:\n",
      "tensor([0.9821], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 46\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9839], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0161])\n",
      "Layer3 output:\n",
      "tensor([0.9839], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 47\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9855], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0145])\n",
      "Layer3 output:\n",
      "tensor([0.9855], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 48\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9869], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0131])\n",
      "Layer3 output:\n",
      "tensor([0.9869], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 49\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9882], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0118])\n",
      "Layer3 output:\n",
      "tensor([0.9882], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 50\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9894], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0106])\n",
      "Layer3 output:\n",
      "tensor([0.9894], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 51\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9905], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0095])\n",
      "Layer3 output:\n",
      "tensor([0.9905], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 52\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9914], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0086])\n",
      "Layer3 output:\n",
      "tensor([0.9914], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 53\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9923], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0077])\n",
      "Layer3 output:\n",
      "tensor([0.9923], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 54\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9930], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0070])\n",
      "Layer3 output:\n",
      "tensor([0.9930], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 55\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9937], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0063])\n",
      "Layer3 output:\n",
      "tensor([0.9937], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 56\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9944], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0056])\n",
      "Layer3 output:\n",
      "tensor([0.9944], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 57\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9949], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0051])\n",
      "Layer3 output:\n",
      "tensor([0.9949], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 58\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9954], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0046])\n",
      "Layer3 output:\n",
      "tensor([0.9954], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 59\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9959], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0041])\n",
      "Layer3 output:\n",
      "tensor([0.9959], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 60\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9963], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0037])\n",
      "Layer3 output:\n",
      "tensor([0.9963], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 61\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9967], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0033])\n",
      "Layer3 output:\n",
      "tensor([0.9967], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 62\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9970], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0030])\n",
      "Layer3 output:\n",
      "tensor([0.9970], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 63\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9973], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0027])\n",
      "Layer3 output:\n",
      "tensor([0.9973], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 64\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9976], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0024])\n",
      "Layer3 output:\n",
      "tensor([0.9976], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 65\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9978], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0022])\n",
      "Layer3 output:\n",
      "tensor([0.9978], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 66\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9980], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0020])\n",
      "Layer3 output:\n",
      "tensor([0.9980], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 67\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9982], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0018])\n",
      "Layer3 output:\n",
      "tensor([0.9982], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 68\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9984], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0016])\n",
      "Layer3 output:\n",
      "tensor([0.9984], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 69\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9986], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0014])\n",
      "Layer3 output:\n",
      "tensor([0.9986], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 70\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9987], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0013])\n",
      "Layer3 output:\n",
      "tensor([0.9987], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 71\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9988], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0012])\n",
      "Layer3 output:\n",
      "tensor([0.9988], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 72\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9990], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0010])\n",
      "Layer3 output:\n",
      "tensor([0.9990], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 73\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9991], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0009])\n",
      "Layer3 output:\n",
      "tensor([0.9991], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 74\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9992], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0008])\n",
      "Layer3 output:\n",
      "tensor([0.9992], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 75\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9992], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0008])\n",
      "Layer3 output:\n",
      "tensor([0.9992], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 76\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9993], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0007])\n",
      "Layer3 output:\n",
      "tensor([0.9993], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 77\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9994], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0006])\n",
      "Layer3 output:\n",
      "tensor([0.9994], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 78\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9994], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0006])\n",
      "Layer3 output:\n",
      "tensor([0.9994], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 79\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9995], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0005])\n",
      "Layer3 output:\n",
      "tensor([0.9995], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 80\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9996], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0004])\n",
      "Layer3 output:\n",
      "tensor([0.9996], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 81\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9996], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0004])\n",
      "Layer3 output:\n",
      "tensor([0.9996], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 82\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9996], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0004])\n",
      "Layer3 output:\n",
      "tensor([0.9996], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 83\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9997], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0003])\n",
      "Layer3 output:\n",
      "tensor([0.9997], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 84\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9997], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0003])\n",
      "Layer3 output:\n",
      "tensor([0.9997], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 85\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9997], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0003])\n",
      "Layer3 output:\n",
      "tensor([0.9997], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 86\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9998], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0002])\n",
      "Layer3 output:\n",
      "tensor([0.9998], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 87\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9998], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0002])\n",
      "Layer3 output:\n",
      "tensor([0.9998], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 88\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9998], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0002])\n",
      "Layer3 output:\n",
      "tensor([0.9998], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 89\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9998], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0002])\n",
      "Layer3 output:\n",
      "tensor([0.9998], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 90\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9998], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0002])\n",
      "Layer3 output:\n",
      "tensor([0.9998], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 91\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0001])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 92\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0001])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 93\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0001])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 94\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-0.0001])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 95\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-9.2506e-05])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 96\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-8.3268e-05])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 97\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-7.4923e-05])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 98\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-6.7413e-05])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 99\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-6.0678e-05])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n",
      "Iters 100\n",
      "Input:\n",
      "tensor([2.])\n",
      "-----------------------\n",
      "-----------------------\n",
      "Layer1 weight Parameter containing:\n",
      "tensor([[-0.4000],\n",
      "        [-0.4000]], requires_grad=True)\n",
      "Layer1 weight Gradient\n",
      "tensor([[0.],\n",
      "        [0.]])\n",
      "Layer1 bias Parameter containing:\n",
      "tensor([-1.2000, -1.2000], requires_grad=True)\n",
      "Layer1 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer1 output:\n",
      "tensor([-2., -2.], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU1 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer2 weight Parameter containing:\n",
      "tensor([[0.4750, 0.4750],\n",
      "        [0.4750, 0.4750]], requires_grad=True)\n",
      "Layer2 weight Gradient\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Layer2 bias Parameter containing:\n",
      "tensor([-0.8500, -0.8500], requires_grad=True)\n",
      "Layer2 bias Gradient\n",
      "tensor([0., 0.])\n",
      "Layer2 output:\n",
      "tensor([-0.8500, -0.8500], grad_fn=<AddBackward0>)\n",
      "-----------------------\n",
      "ReLU2 output:\n",
      "tensor([0., 0.], grad_fn=<ReluBackward0>)\n",
      "-----------------------\n",
      "Layer3 weight Parameter containing:\n",
      "tensor([[0.1250, 0.1250]], requires_grad=True)\n",
      "Layer3 weight Gradient\n",
      "tensor([[0., 0.]])\n",
      "Layer3 bias Parameter containing:\n",
      "tensor([0.9999], requires_grad=True)\n",
      "Layer3 bias Gradient\n",
      "tensor([-5.4598e-05])\n",
      "Layer3 output:\n",
      "tensor([0.9999], grad_fn=<AddBackward0>)\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(OrderedDict([(\"Layer1\", nn.Linear(1, 2)), \n",
    "                                   (\"ReLU1\", nn.ReLU()),\n",
    "                                   (\"Layer2\", nn.Linear(2, 2)), \n",
    "                                   (\"ReLU2\", nn.ReLU()),\n",
    "                                   (\"Layer3\", nn.Linear(2, 1))]))\n",
    "initialize_weights(model)\n",
    "lr = 0.1\n",
    "n_iters = 100\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0)\n",
    "loss_list = []\n",
    "for i in range(n_iters+1):\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(X)\n",
    "    l = loss(pred, y)\n",
    "    loss_list.append(l.detach().numpy())\n",
    "    l.backward()\n",
    "    show_parameters(i, X, model)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
